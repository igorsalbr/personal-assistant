# Server Configuration
APP_PORT=8080
APP_BASE_URL=http://localhost:8080
LOG_LEVEL=info

# LLM Configuration
LLM_PROVIDER=openai  # openai, deepseek, bedrock, mock
LLM_API_KEY=your_openai_api_key_here
LLM_MODEL_CHAT=gpt-3.5-turbo
LLM_MODEL_EMBED=text-embedding-ada-002

# DeepSeek Configuration (if using DeepSeek)
# LLM_PROVIDER=deepseek
# LLM_API_KEY=your_deepseek_api_key_here
# LLM_MODEL_CHAT=deepseek-chat
# LLM_MODEL_EMBED=text-embedding-v1

# AWS Bedrock Configuration (if using Bedrock)
# LLM_PROVIDER=bedrock
# LLM_MODEL_CHAT=anthropic.claude-3-sonnet-20240229-v1:0
# LLM_MODEL_EMBED=amazon.titan-embed-text-v1
# AWS_REGION=us-east-1

# Vector Store Configuration
VECTOR_BACKEND=pgvector  # pgvector, sql_fallback

# Database Configuration
DATABASE_URL_DEFAULT=postgres://user:password@localhost/whatsapp_bot_default?sslmode=disable

# Infobip Configuration
INFOBIP_BASE_URL=https://api.infobip.com
INFOBIP_API_KEY=your_infobip_api_key_here

# Webhook Security
WEBHOOK_VERIFY_TOKEN=your_webhook_verify_token_here

# RAG Configuration
RAG_TOP_K=5
RAG_MIN_SCORE=0.7

# Token Limits
MAX_TOKENS_REPLY=500
SUMMARIZE_THRESHOLD=10000

# Development/Testing
# Use mock provider for testing without API costs
# LLM_PROVIDER=mock
# LLM_API_KEY=mock_key